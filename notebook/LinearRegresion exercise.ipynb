{
 "metadata": {
  "name": "",
  "signature": "sha256:94695bb1323ef956e8ea81a3f0142217b0d23ee8ae4d7c822c8ebba09de835e8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"LinearRegresion Exercise\"\n",
      "print \"Q1\"\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "data = np.array([map(float, l.split()) for l in open('housing.data')])\n",
      "# agafem l' \u00fa\u013atima columna\n",
      "Y = data[:,-1]\n",
      "print \"number of instances\", len (Y)\n",
      "print Y.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LinearRegresion Exercise\n",
        "Q1\n",
        "number of instances 506\n",
        "[ 24.   21.6  34.7  33.4  36.2  28.7  22.9  27.1  16.5  18.9  15.   18.9\n",
        "  21.7  20.4  18.2  19.9  23.1  17.5  20.2  18.2  13.6  19.6  15.2  14.5\n",
        "  15.6  13.9  16.6  14.8  18.4  21.   12.7  14.5  13.2  13.1  13.5  18.9\n",
        "  20.   21.   24.7  30.8  34.9  26.6  25.3  24.7  21.2  19.3  20.   16.6\n",
        "  14.4  19.4  19.7  20.5  25.   23.4  18.9  35.4  24.7  31.6  23.3  19.6\n",
        "  18.7  16.   22.2  25.   33.   23.5  19.4  22.   17.4  20.9  24.2  21.7\n",
        "  22.8  23.4  24.1  21.4  20.   20.8  21.2  20.3  28.   23.9  24.8  22.9\n",
        "  23.9  26.6  22.5  22.2  23.6  28.7  22.6  22.   22.9  25.   20.6  28.4\n",
        "  21.4  38.7  43.8  33.2  27.5  26.5  18.6  19.3  20.1  19.5  19.5  20.4\n",
        "  19.8  19.4  21.7  22.8  18.8  18.7  18.5  18.3  21.2  19.2  20.4  19.3\n",
        "  22.   20.3  20.5  17.3  18.8  21.4  15.7  16.2  18.   14.3  19.2  19.6\n",
        "  23.   18.4  15.6  18.1  17.4  17.1  13.3  17.8  14.   14.4  13.4  15.6\n",
        "  11.8  13.8  15.6  14.6  17.8  15.4  21.5  19.6  15.3  19.4  17.   15.6\n",
        "  13.1  41.3  24.3  23.3  27.   50.   50.   50.   22.7  25.   50.   23.8\n",
        "  23.8  22.3  17.4  19.1  23.1  23.6  22.6  29.4  23.2  24.6  29.9  37.2\n",
        "  39.8  36.2  37.9  32.5  26.4  29.6  50.   32.   29.8  34.9  37.   30.5\n",
        "  36.4  31.1  29.1  50.   33.3  30.3  34.6  34.9  32.9  24.1  42.3  48.5\n",
        "  50.   22.6  24.4  22.5  24.4  20.   21.7  19.3  22.4  28.1  23.7  25.\n",
        "  23.3  28.7  21.5  23.   26.7  21.7  27.5  30.1  44.8  50.   37.6  31.6\n",
        "  46.7  31.5  24.3  31.7  41.7  48.3  29.   24.   25.1  31.5  23.7  23.3\n",
        "  22.   20.1  22.2  23.7  17.6  18.5  24.3  20.5  24.5  26.2  24.4  24.8\n",
        "  29.6  42.8  21.9  20.9  44.   50.   36.   30.1  33.8  43.1  48.8  31.\n",
        "  36.5  22.8  30.7  50.   43.5  20.7  21.1  25.2  24.4  35.2  32.4  32.\n",
        "  33.2  33.1  29.1  35.1  45.4  35.4  46.   50.   32.2  22.   20.1  23.2\n",
        "  22.3  24.8  28.5  37.3  27.9  23.9  21.7  28.6  27.1  20.3  22.5  29.\n",
        "  24.8  22.   26.4  33.1  36.1  28.4  33.4  28.2  22.8  20.3  16.1  22.1\n",
        "  19.4  21.6  23.8  16.2  17.8  19.8  23.1  21.   23.8  23.1  20.4  18.5\n",
        "  25.   24.6  23.   22.2  19.3  22.6  19.8  17.1  19.4  22.2  20.7  21.1\n",
        "  19.5  18.5  20.6  19.   18.7  32.7  16.5  23.9  31.2  17.5  17.2  23.1\n",
        "  24.5  26.6  22.9  24.1  18.6  30.1  18.2  20.6  17.8  21.7  22.7  22.6\n",
        "  25.   19.9  20.8  16.8  21.9  27.5  21.9  23.1  50.   50.   50.   50.\n",
        "  50.   13.8  13.8  15.   13.9  13.3  13.1  10.2  10.4  10.9  11.3  12.3\n",
        "   8.8   7.2  10.5   7.4  10.2  11.5  15.1  23.2   9.7  13.8  12.7  13.1\n",
        "  12.5   8.5   5.    6.3   5.6   7.2  12.1   8.3   8.5   5.   11.9  27.9\n",
        "  17.2  27.5  15.   17.2  17.9  16.3   7.    7.2   7.5  10.4   8.8   8.4\n",
        "  16.7  14.2  20.8  13.4  11.7   8.3  10.2  10.9  11.    9.5  14.5  14.1\n",
        "  16.1  14.3  11.7  13.4   9.6   8.7   8.4  12.8  10.5  17.1  18.4  15.4\n",
        "  10.8  11.8  14.9  12.6  14.1  13.   13.4  15.2  16.1  17.8  14.9  14.1\n",
        "  12.7  13.5  14.9  20.   16.4  17.7  19.5  20.2  21.4  19.9  19.   19.1\n",
        "  19.1  20.1  19.9  19.6  23.2  29.8  13.8  13.3  16.7  12.   14.6  21.4\n",
        "  23.   23.7  25.   21.8  20.6  21.2  19.1  20.6  15.2   7.    8.1  13.6\n",
        "  20.1  21.8  24.5  23.1  19.7  18.3  21.2  17.5  16.8  22.4  20.6  23.9\n",
        "  22.   11.9]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"LinearRegresion Exercise\"\n",
      "print \"Q2\"\n",
      "\n",
      "Y_mean = np.mean(Y)\n",
      "print \"mean is %d\" %(Y_mean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LinearRegresion Exercise\n",
        "Q2\n",
        "mean is 22\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "print \"LinearRegresion Exercise\"\n",
      "print \"Q2\"\n",
      "Y_mean=np.mean(Y)\n",
      "print \"average:\", average"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mse = sum ((Y_mean-Y)**2) / len(Y)\n",
      "print \"mean squared error:\", mse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mean squared error: 84.4195561562\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def MSE(y_p, y):\n",
      "\n",
      "    return np.sum((y-y_p)**2) / len(y)\n",
      "\n",
      "print MSE(Y_mean, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "84.4195561562\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"LinearRegresion Exercise\"\n",
      "print \"Q3\"\n",
      "\n",
      "n = len(Y)/2\n",
      "\n",
      "    \n",
      "traindata = data[:n,:-1]\n",
      "trainY = Y[:n]\n",
      "testdata = data[n:,:-1]\n",
      "testY = Y[:n]\n",
      "    \n",
      "MSEtrain = []\n",
      "MSEtest = []\n",
      "theta = []\n",
      "\n",
      "\n",
      "for i in range(0, len(traindata[0])):\n",
      "\n",
      "    train = np.hstack((np.ones((n,1)), traindata[:, i:i+1]))    \n",
      "    test = np.hstack((np.ones((n,1)), testdata[:, i:i+1]))\n",
      "    theta = np.linalg.lstsq(train, trainY)[0]\n",
      "    MSEtrain.append(MSE(np.dot(train, theta), trainY))\n",
      "    MSEtest.append(MSE(np.dot(test, theta), testY))\n",
      "\n",
      "    R = 1 - MSEtest[i]/np.var(testY)\n",
      "\n",
      "    print \"Columna %d, R=%3.f\" % (i,R)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LinearRegresion Exercise\n",
        "Q3\n",
        "Columna 0, R=-17\n",
        "Columna 1, R= -0\n",
        "Columna 2, R= -0\n",
        "Columna 3, R= -0\n",
        "Columna 4, R= -0\n",
        "Columna 5, R= -1\n",
        "Columna 6, R= -0\n",
        "Columna 7, R= -0\n",
        "Columna 8, R= -0\n",
        "Columna 9, R= -1\n",
        "Columna 10, R= -0\n",
        "Columna 11, R= -1\n",
        "Columna 12, R= -1\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minMSE = []\n",
      "\n",
      "for i in range(len(MSEtrain)):\n",
      "    minMSE.append(abs(MSEtrain[i] - MSEtest[i]))\n",
      "print \"Worst WSE at column %d with value %3.f\" % (np.argmax(MSEtest), np.max(MSEtest))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Worst WSE at column 0 with value 1236\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"LinearRegresion Exercise\"\n",
      "print \"Q4\"\n",
      "train2=traindata[:, 1:]\n",
      "test2=testdata[:,1:]\n",
      "\n",
      "MSEtrain = []\n",
      "MSEtest = []\n",
      "theta = []\n",
      "\n",
      "for i in range(0, len(train2[0])):\n",
      "        train = np.hstack((np.ones((n,1)), train2[:, i:i+1]))\n",
      "        test  = np.hstack((np.ones((n,1)), test2[:, i:i+1]))\n",
      "\n",
      "        theta = np.linalg.lstsq(train, trainY)[0]\n",
      "\n",
      "        MSEtrain.append(MSE(np.dot(train, theta), trainY))\n",
      "        MSEtest.append(MSE(np.dot(test, theta), testY))\n",
      "\n",
      "        R = 1 - MSEtest[i]/np.var(testY)\n",
      "\n",
      "        print \"Columna %d, R=%3.f\" % (i,R)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LinearRegresion Exercise\n",
        "Q4\n",
        "Columna 0, R= -0\n",
        "Columna 1, R= -0\n",
        "Columna 2, R= -0\n",
        "Columna 3, R= -0\n",
        "Columna 4, R= -1\n",
        "Columna 5, R= -0\n",
        "Columna 6, R= -0\n",
        "Columna 7, R= -0\n",
        "Columna 8, R= -1\n",
        "Columna 9, R= -0\n",
        "Columna 10, R= -1\n",
        "Columna 11, R= -1\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minMSE = []\n",
      "\n",
      "for i in range(len(MSEtrain)):\n",
      "    minMSE.append(abs(MSEtrain[i] - MSEtest[i]))\n",
      "\n",
      "print \"Now, worst WSE at column %d with value %3.f\" % (np.argmax(MSEtest), np.max(MSEtest))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Now, worst WSE at column 11 with value 142\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"LinearRegresion Exercise\"\n",
      "print \"Q4\"\n",
      "MSEtrain = []\n",
      "MSEtest = []\n",
      "theta = []\n",
      "\n",
      "for i in range(0, len(traindata[0])):\n",
      "        train = np.hstack((np.ones((n,1)), traindata[:, i:i+1]))\n",
      "        train = np.hstack((train, traindata[:, i:i+1]**2))\n",
      "        train = np.hstack((train, traindata[:, i:i+1]**3))\n",
      "        train = np.hstack((train, traindata[:, i:i+1]**4))\n",
      "\n",
      "        test  = np.hstack((np.ones((n,1)), testdata[:, i:i+1]))\n",
      "        test = np.hstack((test, testdata[:, i:i+1]**2))\n",
      "        test = np.hstack((test, testdata[:, i:i+1]**3))\n",
      "        test = np.hstack((test, testdata[:, i:i+1]**4))\n",
      "\n",
      "        theta = np.linalg.lstsq(train, trainY)[0]\n",
      "\n",
      "        MSEtrain.append(MSE(np.dot(train, theta), trainY))\n",
      "        MSEtest.append(MSE(np.dot(test, theta), testY))\n",
      "\n",
      "        R = 1 - MSEtest[i]/np.var(testY)\n",
      "\n",
      "        print \"Columna %d, R=%3.f\" % (i,R)\n",
      "\n",
      "minMSE = []\n",
      "\n",
      "for i in range(len(MSEtrain)):\n",
      "    minMSE.append(abs(MSEtrain[i] - MSEtest[i]))\n",
      "\n",
      "print \"Worst WSE at column %d with value %3.f\" % (np.argmax(MSEtest), np.max(MSEtest))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LinearRegresion Exercise\n",
        "Q4\n",
        "Columna 0, R=-723020788060\n",
        "Columna 1, R= -0\n",
        "Columna 2, R= -0\n",
        "Columna 3, R= -0\n",
        "Columna 4, R= -0\n",
        "Columna 5, R= -1\n",
        "Columna 6, R= -0\n",
        "Columna 7, R= -0\n",
        "Columna 8, R=-10574\n",
        "Columna 9, R=-3394\n",
        "Columna 10, R= -0\n",
        "Columna 11, R= -2\n",
        "Columna 12, R= -1\n",
        "Worst WSE at column 0 with value 50071549339421\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    }
   ],
   "metadata": {}
  }
 ]
}